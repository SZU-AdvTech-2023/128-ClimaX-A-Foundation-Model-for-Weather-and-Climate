{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\climaX\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Research\\Race\\ClimaX\\src\\climax\\001.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Research/Race/ClimaX/src/climax/001.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mKB_construction\u001b[39;00m \u001b[39mimport\u001b[39;00m KnowledgeBase_Construction\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Research/Race/ClimaX/src/climax/001.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m kb \u001b[39m=\u001b[39m KnowledgeBase_Construction()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Research/Race/ClimaX/src/climax/001.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m net \u001b[39m=\u001b[39m kb\u001b[39m.\u001b[39mNet()\n",
      "File \u001b[1;32md:\\Research\\Race\\ClimaX\\src\\climax\\KB_construction.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m# from pytorch_lightning import LightningModule\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mclimax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mglobal_forecast\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatamodule\u001b[39;00m \u001b[39mimport\u001b[39;00m GlobalForecastDataModule\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mclimax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtamende_arch\u001b[39;00m \u001b[39mimport\u001b[39;00m ClimaX\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mclimax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mglobal_forecast\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodule\u001b[39;00m \u001b[39mimport\u001b[39;00m GlobalForecastModule\n",
      "File \u001b[1;32mD:\\Research\\Race\\ClimaX\\src\\climax\\global_forecast\\datamodule.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningDataModule\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader, IterableDataset\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\climaX\\lib\\site-packages\\torchdata\\__init__.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# All rights reserved.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m \u001b[39mimport\u001b[39;00m _extension  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m datapipes\n\u001b[0;32m     11\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\climaX\\lib\\site-packages\\torchdata\\datapipes\\__init__.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# All rights reserved.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataChunk, functional_datapipe\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39miter\u001b[39m, \u001b[39mmap\u001b[39m, utils\n\u001b[0;32m     11\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mDataChunk\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfunctional_datapipe\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmap\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mutils\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\climaX\\lib\\site-packages\\torchdata\\datapipes\\iter\\__init__.py:101\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miter\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparagraphaggregator\u001b[39;00m \u001b[39mimport\u001b[39;00m ParagraphAggregatorIterDataPipe \u001b[39mas\u001b[39;00m ParagraphAggregator\n\u001b[0;32m     96\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miter\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplain_text_reader\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     97\u001b[0m     CSVDictParserIterDataPipe \u001b[39mas\u001b[39;00m CSVDictParser,\n\u001b[0;32m     98\u001b[0m     CSVParserIterDataPipe \u001b[39mas\u001b[39;00m CSVParser,\n\u001b[0;32m     99\u001b[0m     LineReaderIterDataPipe \u001b[39mas\u001b[39;00m LineReader,\n\u001b[0;32m    100\u001b[0m )\n\u001b[1;32m--> 101\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miter\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrararchiveloader\u001b[39;00m \u001b[39mimport\u001b[39;00m RarArchiveLoaderIterDataPipe \u001b[39mas\u001b[39;00m RarArchiveLoader\n\u001b[0;32m    102\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miter\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrows2columnar\u001b[39;00m \u001b[39mimport\u001b[39;00m Rows2ColumnarIterDataPipe \u001b[39mas\u001b[39;00m Rows2Columnar\n\u001b[0;32m    103\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miter\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msamplemultiplexer\u001b[39;00m \u001b[39mimport\u001b[39;00m SampleMultiplexerDataPipe \u001b[39mas\u001b[39;00m SampleMultiplexer\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\climaX\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\rararchiveloader.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Iterator, Tuple\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39munittest\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmock\u001b[39;00m \u001b[39mimport\u001b[39;00m patch\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m \u001b[39mimport\u001b[39;00m functional_datapipe\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miter\u001b[39;00m \u001b[39mimport\u001b[39;00m IterDataPipe\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\climaX\\lib\\unittest\\__init__.py:60\u001b[0m\n\u001b[0;32m     57\u001b[0m __unittest \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresult\u001b[39;00m \u001b[39mimport\u001b[39;00m TestResult\n\u001b[1;32m---> 60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39masync_case\u001b[39;00m \u001b[39mimport\u001b[39;00m IsolatedAsyncioTestCase\n\u001b[0;32m     61\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcase\u001b[39;00m \u001b[39mimport\u001b[39;00m (addModuleCleanup, TestCase, FunctionTestCase, SkipTest, skip,\n\u001b[0;32m     62\u001b[0m                    skipIf, skipUnless, expectedFailure)\n\u001b[0;32m     63\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msuite\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseTestSuite, TestSuite\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:839\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:934\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1033\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from KB_construction import KnowledgeBase_Construction\n",
    "\n",
    "kb = KnowledgeBase_Construction()\n",
    "net = kb.Net()\n",
    "\n",
    "# from torchsummary import summary\n",
    "\n",
    "# summary(net,input_size=(1,32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, parameter in net.named_parameters():\n",
    "    print(name)\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_embed\n",
      "var_query\n",
      "pos_embed\n",
      "token_embeds.0.proj.weight\n",
      "token_embeds.0.proj.bias\n",
      "token_embeds.1.proj.weight\n",
      "token_embeds.1.proj.bias\n",
      "token_embeds.2.proj.weight\n",
      "token_embeds.2.proj.bias\n",
      "token_embeds.3.proj.weight\n",
      "token_embeds.3.proj.bias\n",
      "token_embeds.4.proj.weight\n",
      "token_embeds.4.proj.bias\n",
      "token_embeds.5.proj.weight\n",
      "token_embeds.5.proj.bias\n",
      "token_embeds.6.proj.weight\n",
      "token_embeds.6.proj.bias\n",
      "token_embeds.7.proj.weight\n",
      "token_embeds.7.proj.bias\n",
      "token_embeds.8.proj.weight\n",
      "token_embeds.8.proj.bias\n",
      "token_embeds.9.proj.weight\n",
      "token_embeds.9.proj.bias\n",
      "token_embeds.10.proj.weight\n",
      "token_embeds.10.proj.bias\n",
      "token_embeds.11.proj.weight\n",
      "token_embeds.11.proj.bias\n",
      "token_embeds.12.proj.weight\n",
      "token_embeds.12.proj.bias\n",
      "token_embeds.13.proj.weight\n",
      "token_embeds.13.proj.bias\n",
      "token_embeds.14.proj.weight\n",
      "token_embeds.14.proj.bias\n",
      "token_embeds.15.proj.weight\n",
      "token_embeds.15.proj.bias\n",
      "token_embeds.16.proj.weight\n",
      "token_embeds.16.proj.bias\n",
      "token_embeds.17.proj.weight\n",
      "token_embeds.17.proj.bias\n",
      "token_embeds.18.proj.weight\n",
      "token_embeds.18.proj.bias\n",
      "token_embeds.19.proj.weight\n",
      "token_embeds.19.proj.bias\n",
      "token_embeds.20.proj.weight\n",
      "token_embeds.20.proj.bias\n",
      "token_embeds.21.proj.weight\n",
      "token_embeds.21.proj.bias\n",
      "token_embeds.22.proj.weight\n",
      "token_embeds.22.proj.bias\n",
      "token_embeds.23.proj.weight\n",
      "token_embeds.23.proj.bias\n",
      "token_embeds.24.proj.weight\n",
      "token_embeds.24.proj.bias\n",
      "token_embeds.25.proj.weight\n",
      "token_embeds.25.proj.bias\n",
      "token_embeds.26.proj.weight\n",
      "token_embeds.26.proj.bias\n",
      "token_embeds.27.proj.weight\n",
      "token_embeds.27.proj.bias\n",
      "token_embeds.28.proj.weight\n",
      "token_embeds.28.proj.bias\n",
      "token_embeds.29.proj.weight\n",
      "token_embeds.29.proj.bias\n",
      "token_embeds.30.proj.weight\n",
      "token_embeds.30.proj.bias\n",
      "token_embeds.31.proj.weight\n",
      "token_embeds.31.proj.bias\n",
      "token_embeds.32.proj.weight\n",
      "token_embeds.32.proj.bias\n",
      "token_embeds.33.proj.weight\n",
      "token_embeds.33.proj.bias\n",
      "token_embeds.34.proj.weight\n",
      "token_embeds.34.proj.bias\n",
      "token_embeds.35.proj.weight\n",
      "token_embeds.35.proj.bias\n",
      "token_embeds.36.proj.weight\n",
      "token_embeds.36.proj.bias\n",
      "token_embeds.37.proj.weight\n",
      "token_embeds.37.proj.bias\n",
      "token_embeds.38.proj.weight\n",
      "token_embeds.38.proj.bias\n",
      "token_embeds.39.proj.weight\n",
      "token_embeds.39.proj.bias\n",
      "token_embeds.40.proj.weight\n",
      "token_embeds.40.proj.bias\n",
      "token_embeds.41.proj.weight\n",
      "token_embeds.41.proj.bias\n",
      "token_embeds.42.proj.weight\n",
      "token_embeds.42.proj.bias\n",
      "token_embeds.43.proj.weight\n",
      "token_embeds.43.proj.bias\n",
      "token_embeds.44.proj.weight\n",
      "token_embeds.44.proj.bias\n",
      "token_embeds.45.proj.weight\n",
      "token_embeds.45.proj.bias\n",
      "token_embeds.46.proj.weight\n",
      "token_embeds.46.proj.bias\n",
      "token_embeds.47.proj.weight\n",
      "token_embeds.47.proj.bias\n",
      "var_agg.in_proj_weight\n",
      "var_agg.in_proj_bias\n",
      "var_agg.out_proj.weight\n",
      "var_agg.out_proj.bias\n",
      "lead_time_embed.weight\n",
      "lead_time_embed.bias\n",
      "blocks.0.norm1.weight\n",
      "blocks.0.norm1.bias\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.norm2.weight\n",
      "blocks.0.norm2.bias\n",
      "blocks.0.mlp.fc1.weight\n",
      "blocks.0.mlp.fc1.bias\n",
      "blocks.0.mlp.fc2.weight\n",
      "blocks.0.mlp.fc2.bias\n",
      "blocks.1.norm1.weight\n",
      "blocks.1.norm1.bias\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.norm2.weight\n",
      "blocks.1.norm2.bias\n",
      "blocks.1.mlp.fc1.weight\n",
      "blocks.1.mlp.fc1.bias\n",
      "blocks.1.mlp.fc2.weight\n",
      "blocks.1.mlp.fc2.bias\n",
      "blocks.2.norm1.weight\n",
      "blocks.2.norm1.bias\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.norm2.weight\n",
      "blocks.2.norm2.bias\n",
      "blocks.2.mlp.fc1.weight\n",
      "blocks.2.mlp.fc1.bias\n",
      "blocks.2.mlp.fc2.weight\n",
      "blocks.2.mlp.fc2.bias\n",
      "blocks.3.norm1.weight\n",
      "blocks.3.norm1.bias\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.norm2.weight\n",
      "blocks.3.norm2.bias\n",
      "blocks.3.mlp.fc1.weight\n",
      "blocks.3.mlp.fc1.bias\n",
      "blocks.3.mlp.fc2.weight\n",
      "blocks.3.mlp.fc2.bias\n",
      "blocks.4.norm1.weight\n",
      "blocks.4.norm1.bias\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.norm2.weight\n",
      "blocks.4.norm2.bias\n",
      "blocks.4.mlp.fc1.weight\n",
      "blocks.4.mlp.fc1.bias\n",
      "blocks.4.mlp.fc2.weight\n",
      "blocks.4.mlp.fc2.bias\n",
      "blocks.5.norm1.weight\n",
      "blocks.5.norm1.bias\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.norm2.weight\n",
      "blocks.5.norm2.bias\n",
      "blocks.5.mlp.fc1.weight\n",
      "blocks.5.mlp.fc1.bias\n",
      "blocks.5.mlp.fc2.weight\n",
      "blocks.5.mlp.fc2.bias\n",
      "blocks.6.norm1.weight\n",
      "blocks.6.norm1.bias\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.norm2.weight\n",
      "blocks.6.norm2.bias\n",
      "blocks.6.mlp.fc1.weight\n",
      "blocks.6.mlp.fc1.bias\n",
      "blocks.6.mlp.fc2.weight\n",
      "blocks.6.mlp.fc2.bias\n",
      "blocks.7.norm1.weight\n",
      "blocks.7.norm1.bias\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.norm2.weight\n",
      "blocks.7.norm2.bias\n",
      "blocks.7.mlp.fc1.weight\n",
      "blocks.7.mlp.fc1.bias\n",
      "blocks.7.mlp.fc2.weight\n",
      "blocks.7.mlp.fc2.bias\n",
      "norm.weight\n",
      "norm.bias\n",
      "head.0.weight\n",
      "head.0.bias\n",
      "head.2.weight\n",
      "head.2.bias\n",
      "head.4.weight\n",
      "head.4.bias\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in net.named_parameters():\n",
    "    print(name)\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(model):\n",
    "    for module in model.children():\n",
    "        print(module)\n",
    "        if hasattr(module, 'weight'):\n",
    "            print(module.weight.shape)\n",
    "        print_shape(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (1): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (2): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (3): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (4): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (5): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (6): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (7): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (8): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (9): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (10): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (11): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (12): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (13): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (14): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (15): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (16): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (17): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (18): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (19): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (20): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (21): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (22): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (23): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (24): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (25): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (26): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (27): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (28): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (29): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (30): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (31): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (32): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (33): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (34): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (35): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (36): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (37): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (38): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (39): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (40): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (41): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (42): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (43): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (44): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (45): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (46): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (47): PatchEmbed(\n",
      "    (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): Identity()\n",
      "  )\n",
      ")\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "PatchEmbed(\n",
      "  (proj): Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (norm): Identity()\n",
      ")\n",
      "Conv2d(1, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "torch.Size([1024, 1, 2, 2])\n",
      "Identity()\n",
      "MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      ")\n",
      "NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "Linear(in_features=1, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "ModuleList(\n",
      "  (0): Block(\n",
      "    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (drop1): Dropout(p=0.1, inplace=False)\n",
      "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (drop2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (1): Block(\n",
      "    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): DropPath(drop_prob=0.014)\n",
      "    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (drop1): Dropout(p=0.1, inplace=False)\n",
      "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (drop2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): DropPath(drop_prob=0.014)\n",
      "  )\n",
      "  (2): Block(\n",
      "    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): DropPath(drop_prob=0.029)\n",
      "    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (drop1): Dropout(p=0.1, inplace=False)\n",
      "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (drop2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): DropPath(drop_prob=0.029)\n",
      "  )\n",
      "  (3): Block(\n",
      "    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): DropPath(drop_prob=0.043)\n",
      "    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (drop1): Dropout(p=0.1, inplace=False)\n",
      "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (drop2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): DropPath(drop_prob=0.043)\n",
      "  )\n",
      "  (4): Block(\n",
      "    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): DropPath(drop_prob=0.057)\n",
      "    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (drop1): Dropout(p=0.1, inplace=False)\n",
      "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (drop2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): DropPath(drop_prob=0.057)\n",
      "  )\n",
      "  (5): Block(\n",
      "    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): DropPath(drop_prob=0.071)\n",
      "    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (drop1): Dropout(p=0.1, inplace=False)\n",
      "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (drop2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): DropPath(drop_prob=0.071)\n",
      "  )\n",
      "  (6): Block(\n",
      "    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): DropPath(drop_prob=0.086)\n",
      "    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (drop1): Dropout(p=0.1, inplace=False)\n",
      "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (drop2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): DropPath(drop_prob=0.086)\n",
      "  )\n",
      "  (7): Block(\n",
      "    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): DropPath(drop_prob=0.100)\n",
      "    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (drop1): Dropout(p=0.1, inplace=False)\n",
      "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (drop2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): DropPath(drop_prob=0.100)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls1): Identity()\n",
      "  (drop_path1): Identity()\n",
      "  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (drop1): Dropout(p=0.1, inplace=False)\n",
      "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (drop2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls2): Identity()\n",
      "  (drop_path2): Identity()\n",
      ")\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Attention(\n",
      "  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=3072, bias=True)\n",
      "torch.Size([3072, 1024])\n",
      "Dropout(p=0.0, inplace=False)\n",
      "Linear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "Identity()\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Mlp(\n",
      "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (drop1): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (drop2): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=4096, bias=True)\n",
      "torch.Size([4096, 1024])\n",
      "GELU(approximate=none)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Linear(in_features=4096, out_features=1024, bias=True)\n",
      "torch.Size([1024, 4096])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "Identity()\n",
      "Block(\n",
      "  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls1): Identity()\n",
      "  (drop_path1): DropPath(drop_prob=0.014)\n",
      "  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (drop1): Dropout(p=0.1, inplace=False)\n",
      "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (drop2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls2): Identity()\n",
      "  (drop_path2): DropPath(drop_prob=0.014)\n",
      ")\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Attention(\n",
      "  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=3072, bias=True)\n",
      "torch.Size([3072, 1024])\n",
      "Dropout(p=0.0, inplace=False)\n",
      "Linear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.014)\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Mlp(\n",
      "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (drop1): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (drop2): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=4096, bias=True)\n",
      "torch.Size([4096, 1024])\n",
      "GELU(approximate=none)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Linear(in_features=4096, out_features=1024, bias=True)\n",
      "torch.Size([1024, 4096])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.014)\n",
      "Block(\n",
      "  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls1): Identity()\n",
      "  (drop_path1): DropPath(drop_prob=0.029)\n",
      "  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (drop1): Dropout(p=0.1, inplace=False)\n",
      "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (drop2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls2): Identity()\n",
      "  (drop_path2): DropPath(drop_prob=0.029)\n",
      ")\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Attention(\n",
      "  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=3072, bias=True)\n",
      "torch.Size([3072, 1024])\n",
      "Dropout(p=0.0, inplace=False)\n",
      "Linear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.029)\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Mlp(\n",
      "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (drop1): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (drop2): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=4096, bias=True)\n",
      "torch.Size([4096, 1024])\n",
      "GELU(approximate=none)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Linear(in_features=4096, out_features=1024, bias=True)\n",
      "torch.Size([1024, 4096])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.029)\n",
      "Block(\n",
      "  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls1): Identity()\n",
      "  (drop_path1): DropPath(drop_prob=0.043)\n",
      "  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (drop1): Dropout(p=0.1, inplace=False)\n",
      "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (drop2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls2): Identity()\n",
      "  (drop_path2): DropPath(drop_prob=0.043)\n",
      ")\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Attention(\n",
      "  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=3072, bias=True)\n",
      "torch.Size([3072, 1024])\n",
      "Dropout(p=0.0, inplace=False)\n",
      "Linear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.043)\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Mlp(\n",
      "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (drop1): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (drop2): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=4096, bias=True)\n",
      "torch.Size([4096, 1024])\n",
      "GELU(approximate=none)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Linear(in_features=4096, out_features=1024, bias=True)\n",
      "torch.Size([1024, 4096])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.043)\n",
      "Block(\n",
      "  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls1): Identity()\n",
      "  (drop_path1): DropPath(drop_prob=0.057)\n",
      "  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (drop1): Dropout(p=0.1, inplace=False)\n",
      "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (drop2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls2): Identity()\n",
      "  (drop_path2): DropPath(drop_prob=0.057)\n",
      ")\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Attention(\n",
      "  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=3072, bias=True)\n",
      "torch.Size([3072, 1024])\n",
      "Dropout(p=0.0, inplace=False)\n",
      "Linear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.057)\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Mlp(\n",
      "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (drop1): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (drop2): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=4096, bias=True)\n",
      "torch.Size([4096, 1024])\n",
      "GELU(approximate=none)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Linear(in_features=4096, out_features=1024, bias=True)\n",
      "torch.Size([1024, 4096])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.057)\n",
      "Block(\n",
      "  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls1): Identity()\n",
      "  (drop_path1): DropPath(drop_prob=0.071)\n",
      "  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (drop1): Dropout(p=0.1, inplace=False)\n",
      "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (drop2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls2): Identity()\n",
      "  (drop_path2): DropPath(drop_prob=0.071)\n",
      ")\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Attention(\n",
      "  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=3072, bias=True)\n",
      "torch.Size([3072, 1024])\n",
      "Dropout(p=0.0, inplace=False)\n",
      "Linear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.071)\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Mlp(\n",
      "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (drop1): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (drop2): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=4096, bias=True)\n",
      "torch.Size([4096, 1024])\n",
      "GELU(approximate=none)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Linear(in_features=4096, out_features=1024, bias=True)\n",
      "torch.Size([1024, 4096])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.071)\n",
      "Block(\n",
      "  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls1): Identity()\n",
      "  (drop_path1): DropPath(drop_prob=0.086)\n",
      "  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (drop1): Dropout(p=0.1, inplace=False)\n",
      "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (drop2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls2): Identity()\n",
      "  (drop_path2): DropPath(drop_prob=0.086)\n",
      ")\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Attention(\n",
      "  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=3072, bias=True)\n",
      "torch.Size([3072, 1024])\n",
      "Dropout(p=0.0, inplace=False)\n",
      "Linear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.086)\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Mlp(\n",
      "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (drop1): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (drop2): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=4096, bias=True)\n",
      "torch.Size([4096, 1024])\n",
      "GELU(approximate=none)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Linear(in_features=4096, out_features=1024, bias=True)\n",
      "torch.Size([1024, 4096])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.086)\n",
      "Block(\n",
      "  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls1): Identity()\n",
      "  (drop_path1): DropPath(drop_prob=0.100)\n",
      "  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (drop1): Dropout(p=0.1, inplace=False)\n",
      "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (drop2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ls2): Identity()\n",
      "  (drop_path2): DropPath(drop_prob=0.100)\n",
      ")\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Attention(\n",
      "  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=3072, bias=True)\n",
      "torch.Size([3072, 1024])\n",
      "Dropout(p=0.0, inplace=False)\n",
      "Linear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.100)\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Mlp(\n",
      "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (drop1): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (drop2): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=1024, out_features=4096, bias=True)\n",
      "torch.Size([4096, 1024])\n",
      "GELU(approximate=none)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Linear(in_features=4096, out_features=1024, bias=True)\n",
      "torch.Size([1024, 4096])\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Identity()\n",
      "DropPath(drop_prob=0.100)\n",
      "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "torch.Size([1024])\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (3): GELU(approximate=none)\n",
      "  (4): Linear(in_features=1024, out_features=192, bias=True)\n",
      ")\n",
      "Linear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "GELU(approximate=none)\n",
      "Linear(in_features=1024, out_features=1024, bias=True)\n",
      "torch.Size([1024, 1024])\n",
      "GELU(approximate=none)\n",
      "Linear(in_features=1024, out_features=192, bias=True)\n",
      "torch.Size([192, 1024])\n"
     ]
    }
   ],
   "source": [
    "print_shape(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 4, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn \n",
    "import torch\n",
    "nn.LazyBatchNorm2d()(torch.rand([6,3,4,5])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "x = torch.randn([1, 512, 1024])\n",
    "X = x[0]\n",
    "X= X.T\n",
    "X = X.cpu().numpy()\n",
    "pca=PCA(n_components=1)\n",
    "pca.fit(X)\n",
    "a =pca.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(a.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 122, 250])\n",
      "torch.Size([1, 1, 512, 1024])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7) \n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        print(x.shape)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# 输入形状[512, 1024]    \n",
    "x = torch.rand(1, 1, 512, 1024) \n",
    "\n",
    "model = AutoEncoder()\n",
    "output = model(x)\n",
    "print(output.shape) # torch.Size([1, 1, 512, 1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 1024])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([32,512, 1024])\n",
    "x.view(x.size(0), 512, 32 ,32)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained checkpoint from: D:\\Research\\Race\\ClimaX\\${trainer.default_root_dir}\\checkpoints\\epoch_002.ckpt\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "from climax.KB_construction import KnowledgeBase_Construction\n",
    "kb = KnowledgeBase_Construction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.data_loader.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b= kb.return_AE_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<climax.pretrain.dataset.ShuffleIterableDataset at 0x2ccbcc3fdc0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "flatten() has invalid args: start_dim cannot come after end_dim",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Research\\Race\\ClimaX\\src\\climax\\001.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Research/Race/ClimaX/src/climax/001.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Research/Race/ClimaX/src/climax/001.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn([\u001b[39m16\u001b[39m, \u001b[39m512\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Research/Race/ClimaX/src/climax/001.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m a\u001b[39m=\u001b[39m a\u001b[39m.\u001b[39;49mflatten(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Research/Race/ClimaX/src/climax/001.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(a, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Research/Race/ClimaX/src/climax/001.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m a\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: flatten() has invalid args: start_dim cannot come after end_dim"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "a = torch.randn([16, 512, 32, 32])\n",
    "a= a.flatten(-1,1)\n",
    "a = torch.softmax(a, dim=-1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8592])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn([8592, 2048])\n",
    "b = torch.randn([32, 2048])\n",
    "ans = torch.matmul(b, a.T)\n",
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, c) -> None:\n",
    "        super(AE, self).__init__()\n",
    "        \n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 5, 2, 2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256, 128, 5, 2, 2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, c, 3, 1, 1),\n",
    "            nn.BatchNorm2d(c),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(c, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(128, 256, 5, 2, 2, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(256, 512, 5, 2, 2, output_padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x \n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.Encoder(x).view(x.size(0), -1)\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.Decoder(x).view(x.size(0),-1,-1)\n",
    "    \n",
    "\n",
    "ae = AE(c=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.9787e+03,  1.0109e+03,  1.6182e+03,  ...,  1.7960e+02,\n",
       "            8.4165e+01, -1.4503e+02],\n",
       "          [-5.5434e+02, -1.8914e+03, -1.0255e+03,  ..., -2.3902e+01,\n",
       "            1.9610e+03, -1.0020e+03],\n",
       "          [-2.6572e+02, -1.2561e+03, -1.0259e+03,  ...,  1.5718e+02,\n",
       "            2.4706e+02,  1.4724e+03],\n",
       "          ...,\n",
       "          [ 4.0529e+02,  5.8203e+02,  9.5420e+02,  ..., -1.1871e+03,\n",
       "           -1.2895e+02, -9.6721e+02],\n",
       "          [ 2.5173e+02,  9.5534e+02, -6.1813e+02,  ...,  1.7751e+03,\n",
       "           -1.7272e+03, -5.8999e+01],\n",
       "          [ 5.2022e+02, -2.4901e+02,  5.4471e+02,  ..., -1.6995e+02,\n",
       "            1.7443e+01,  5.4610e+02]],\n",
       "\n",
       "         [[-1.3244e+03,  1.1293e+03,  3.9615e+02,  ..., -1.2846e+03,\n",
       "            3.9910e+02,  9.9422e+02],\n",
       "          [-3.5464e+02,  2.2609e+03, -4.7630e+02,  ...,  2.6843e+03,\n",
       "           -2.0076e+02,  7.3779e+02],\n",
       "          [ 9.2898e+01, -2.7329e+02,  1.2264e+02,  ...,  4.6385e+02,\n",
       "            2.1037e+03,  2.0984e+02],\n",
       "          ...,\n",
       "          [-1.0870e+03, -1.2880e+03, -3.8716e+02,  ..., -5.2109e+02,\n",
       "           -1.2783e+02,  1.8211e+03],\n",
       "          [-1.3398e+03, -3.7661e+02,  2.9379e+02,  ..., -4.0933e+02,\n",
       "           -5.5470e+02,  5.7680e+02],\n",
       "          [ 1.4341e+02,  1.3191e+03,  2.4808e+02,  ..., -5.7007e+02,\n",
       "           -5.7846e+02,  8.6489e+02]],\n",
       "\n",
       "         [[ 4.4542e+02, -5.4145e+01, -3.4412e+02,  ..., -1.2313e+03,\n",
       "            2.0721e+02, -9.0598e+02],\n",
       "          [ 1.0610e+03,  1.2454e+02,  4.2687e+02,  ...,  2.3669e+03,\n",
       "           -2.9162e+02,  1.6670e+03],\n",
       "          [ 5.8905e+02,  5.9373e+02,  6.0525e+02,  ...,  5.0444e+02,\n",
       "           -5.4677e+01,  8.2249e+02],\n",
       "          ...,\n",
       "          [ 1.0142e+03,  3.3236e+02,  1.7628e+02,  ...,  2.8105e+02,\n",
       "            1.2193e+03, -1.7808e+03],\n",
       "          [ 2.8971e+02, -9.0837e+02, -6.4126e+02,  ..., -1.2946e+03,\n",
       "           -8.8918e+02,  9.1614e+02],\n",
       "          [-6.7371e+02,  2.7183e+02, -5.0470e+02,  ..., -4.8020e+02,\n",
       "            5.2099e+02, -6.7510e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.1270e+01,  1.0183e+03,  3.4185e+02,  ..., -6.6726e+02,\n",
       "           -6.3818e+02,  2.5941e+03],\n",
       "          [ 1.3568e+03, -6.7741e+02,  7.3847e+02,  ...,  4.6318e+02,\n",
       "           -4.9050e+01,  1.6811e+03],\n",
       "          [-2.9224e+02,  8.5854e+02,  1.5344e+03,  ...,  7.4931e+02,\n",
       "           -4.1845e+02,  8.2386e+02],\n",
       "          ...,\n",
       "          [-8.4981e+02,  1.3769e+03, -2.1532e+02,  ...,  1.8926e+02,\n",
       "           -8.7628e+01, -1.2183e+03],\n",
       "          [ 6.8587e+02,  2.0895e+03, -7.6072e+02,  ..., -2.9858e+02,\n",
       "            1.9133e+02,  1.3252e+03],\n",
       "          [-8.4100e+02, -1.6297e+02, -7.1059e+02,  ...,  3.4459e+02,\n",
       "           -4.3466e+02, -3.9892e+02]],\n",
       "\n",
       "         [[ 1.2779e+02, -1.0950e+03,  2.2199e+02,  ..., -5.6845e+01,\n",
       "            1.8022e+02,  1.4780e+03],\n",
       "          [ 1.4195e+03, -1.0101e+03, -1.7401e+03,  ..., -4.5789e+02,\n",
       "           -7.7519e+02, -3.1265e+02],\n",
       "          [ 1.2737e+03,  7.1693e+02, -3.2773e+02,  ...,  1.1982e+03,\n",
       "           -6.3495e+01,  1.5312e+03],\n",
       "          ...,\n",
       "          [ 1.3603e+03, -6.1654e+02, -2.1576e+02,  ...,  4.1230e+02,\n",
       "           -2.9820e+02,  7.6013e+02],\n",
       "          [ 1.6774e+02, -3.2350e+03,  1.8182e+02,  ..., -2.1613e+02,\n",
       "            1.2148e+03,  1.7228e+03],\n",
       "          [ 3.3396e+01, -9.1999e+02, -5.0900e+02,  ..., -1.6214e+02,\n",
       "            1.0379e+03,  1.3865e+03]],\n",
       "\n",
       "         [[-1.2761e+02, -7.7701e+02,  7.2887e+02,  ..., -5.5561e+02,\n",
       "           -1.5090e+03, -7.4858e+02],\n",
       "          [-1.6028e+03, -9.7262e+02, -1.1232e+03,  ...,  5.4842e+02,\n",
       "            8.6143e+02,  2.4859e+02],\n",
       "          [ 1.1310e+02,  5.4055e+00, -5.5425e+02,  ..., -2.4268e+02,\n",
       "           -3.2290e+02, -1.3834e+03],\n",
       "          ...,\n",
       "          [-5.9243e+02,  3.8244e+02,  1.8295e+01,  ..., -1.8248e+02,\n",
       "           -1.2544e+03,  1.0377e+03],\n",
       "          [ 3.9250e+02, -8.7989e+02,  7.0293e+02,  ...,  1.2732e+02,\n",
       "            2.0535e+02, -1.0510e+03],\n",
       "          [-3.0551e+02,  4.5566e+01,  8.2800e+01,  ..., -1.0235e+03,\n",
       "           -4.5681e+01,  1.6568e+01]]],\n",
       "\n",
       "\n",
       "        [[[-2.2787e+02,  4.9313e+02, -2.3048e+03,  ...,  2.7755e+02,\n",
       "            8.6301e+02,  5.1594e+02],\n",
       "          [-9.4483e+02, -1.0108e+03, -1.9353e+02,  ..., -5.1604e+02,\n",
       "           -9.7893e+01,  1.1013e+03],\n",
       "          [-8.4524e+02,  2.9770e+02, -4.2592e+02,  ...,  8.5329e+01,\n",
       "           -2.7429e+03, -1.5107e+03],\n",
       "          ...,\n",
       "          [-9.9859e+01, -9.6170e+02, -6.3679e+02,  ...,  1.5266e+03,\n",
       "            1.6498e+03,  2.7806e+02],\n",
       "          [-1.2870e+03,  3.4824e+02, -6.7918e+02,  ..., -1.5680e+03,\n",
       "            3.2518e+02, -7.5258e+02],\n",
       "          [-3.1822e+02, -5.0908e+02,  4.9132e+02,  ..., -2.9179e+02,\n",
       "           -1.3749e+03,  6.0718e+01]],\n",
       "\n",
       "         [[-1.0427e+03, -6.9080e+02, -4.2726e+02,  ...,  8.9121e+02,\n",
       "           -6.2190e+02,  2.2159e+03],\n",
       "          [-1.6636e+02, -1.3284e+03,  7.9489e+02,  ..., -3.1662e+02,\n",
       "            1.3888e+03,  1.0216e+03],\n",
       "          [ 3.2324e+02, -2.3421e+02, -2.6225e+03,  ..., -6.8920e+02,\n",
       "           -4.6483e+02,  1.1533e+03],\n",
       "          ...,\n",
       "          [-1.1944e+02, -9.9249e+02,  6.1885e+02,  ..., -1.5087e+03,\n",
       "            3.7510e+02, -4.9403e+02],\n",
       "          [-6.0419e+02, -5.3939e+02, -1.1130e+02,  ...,  1.3611e+03,\n",
       "           -1.0503e+03,  5.4763e+01],\n",
       "          [-1.0903e+03,  5.4692e+02,  7.4134e+02,  ..., -1.8984e+03,\n",
       "           -1.6480e+02,  1.0097e+03]],\n",
       "\n",
       "         [[-1.0473e+03, -1.0790e+03,  7.5139e+02,  ...,  4.2069e+02,\n",
       "            7.6253e+02, -1.8724e+02],\n",
       "          [-1.6293e+03, -1.2273e+03, -5.2569e+02,  ..., -3.4311e+02,\n",
       "           -4.0425e+02, -1.7013e+02],\n",
       "          [ 8.1812e+02, -1.2525e+03, -1.4012e+03,  ...,  1.3833e+03,\n",
       "           -7.2804e+02, -1.2782e+03],\n",
       "          ...,\n",
       "          [-1.8606e+03,  2.8425e+02,  4.7041e+02,  ...,  2.3433e+02,\n",
       "           -8.6389e+02,  2.4348e+02],\n",
       "          [ 1.2796e+03,  8.5507e+02, -7.5979e+02,  ...,  3.9736e+02,\n",
       "            7.9605e+02,  1.2347e+03],\n",
       "          [ 4.0660e+02, -7.5953e+02, -1.1658e+03,  ..., -3.6840e+02,\n",
       "            4.1121e+02, -1.3429e+03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.6086e+02,  1.2000e+03,  4.9022e+01,  ...,  1.1569e+03,\n",
       "            7.0482e+02, -8.3058e+02],\n",
       "          [-1.5239e+03,  1.9967e+03, -2.1891e+02,  ...,  3.7969e+02,\n",
       "            1.0149e+03,  1.0180e+03],\n",
       "          [-1.3575e+03, -1.0018e+03, -1.4719e+03,  ...,  5.0591e+02,\n",
       "            7.0009e+02, -2.4984e+03],\n",
       "          ...,\n",
       "          [-1.8498e+03,  3.8236e+02,  3.2466e+02,  ..., -1.7779e+01,\n",
       "           -1.5498e+03,  4.7681e+02],\n",
       "          [-1.1109e+03,  8.9046e+02,  1.7719e+03,  ...,  7.9401e+02,\n",
       "           -3.7073e+02, -1.4127e+03],\n",
       "          [ 5.9647e+02, -2.4790e+02, -9.3213e+02,  ..., -2.5926e+01,\n",
       "           -1.1067e+03,  1.6160e+02]],\n",
       "\n",
       "         [[-7.5123e+02,  1.1644e+02, -3.3455e+02,  ...,  1.6587e+03,\n",
       "            5.4285e+02,  1.0454e+03],\n",
       "          [-1.1365e+02, -1.1925e+03, -1.1013e+03,  ...,  1.4590e+03,\n",
       "           -6.2571e+02, -7.7382e+02],\n",
       "          [-9.0360e+02, -1.6316e+02, -5.7904e+01,  ...,  6.3999e+02,\n",
       "           -1.6701e+03, -5.0946e+01],\n",
       "          ...,\n",
       "          [ 6.1070e+02, -1.6929e+02,  1.9036e+03,  ..., -1.1955e+03,\n",
       "            5.5132e+02, -6.8353e+02],\n",
       "          [ 5.5674e+02,  5.7863e+02,  9.8662e+02,  ..., -1.5607e+03,\n",
       "            3.1653e+02, -1.6653e+03],\n",
       "          [ 1.1047e+03,  4.7876e+02, -4.5358e+02,  ...,  1.3049e+03,\n",
       "           -4.4037e+02,  2.4964e+03]],\n",
       "\n",
       "         [[ 8.0983e+02,  4.5924e+02, -4.5839e+02,  ..., -2.1200e+02,\n",
       "           -1.0241e+03, -2.2628e+02],\n",
       "          [-1.0573e+02, -2.2547e+02, -1.8370e+02,  ..., -1.0253e+03,\n",
       "           -6.2718e+02, -8.3011e+02],\n",
       "          [ 2.2242e+02,  3.3574e+02, -1.5446e+03,  ..., -1.0417e+03,\n",
       "           -5.9711e+02, -3.8028e+01],\n",
       "          ...,\n",
       "          [-4.6392e+01,  9.7684e+02,  2.3647e+02,  ..., -1.3908e+02,\n",
       "            8.6559e+02, -6.3150e+02],\n",
       "          [ 1.5653e+02, -3.7304e+02,  5.8531e+01,  ..., -1.7794e+03,\n",
       "            1.2391e+03, -9.6667e+02],\n",
       "          [-2.0611e+03,  2.5367e+02,  8.5697e+02,  ...,  6.4818e+01,\n",
       "           -8.5439e+02, -4.6510e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.1663e+02,  4.6239e+01,  7.2636e+01,  ...,  2.8087e+02,\n",
       "           -1.3958e+03,  7.6537e+02],\n",
       "          [-1.1336e+03, -3.6169e+02, -4.4562e+02,  ...,  3.2588e+02,\n",
       "            1.4653e+02,  7.2198e+02],\n",
       "          [ 8.3322e+02,  3.0264e+02,  4.6681e+02,  ..., -5.1676e+02,\n",
       "           -9.2815e+02, -1.8969e+02],\n",
       "          ...,\n",
       "          [ 9.5253e+02,  2.9079e+02, -8.8863e+01,  ...,  4.2075e+02,\n",
       "            3.9244e+02,  5.0090e+02],\n",
       "          [ 2.3920e+03, -1.3947e+03, -6.9799e+02,  ..., -7.1831e+02,\n",
       "           -5.8201e+02,  1.2131e+03],\n",
       "          [-9.6094e+02,  2.1281e+03,  1.4640e+03,  ..., -5.1934e+01,\n",
       "            1.5890e+03, -4.1687e+02]],\n",
       "\n",
       "         [[-2.4570e+02,  6.5873e+02, -3.5042e+02,  ...,  1.2776e+03,\n",
       "            4.2831e+02,  7.0352e+02],\n",
       "          [ 3.8103e+02,  1.6623e+03,  1.8268e+03,  ..., -9.1471e+02,\n",
       "            1.6180e+02,  1.3754e+03],\n",
       "          [ 1.2979e+02, -6.0670e+01,  2.1620e+02,  ..., -1.8350e+03,\n",
       "           -3.4556e+02, -2.7443e+02],\n",
       "          ...,\n",
       "          [-7.4184e+01,  1.6377e+03, -6.3706e+02,  ...,  4.4159e+02,\n",
       "           -8.9382e+02, -1.9012e+03],\n",
       "          [ 5.6440e+02, -2.1320e+03, -2.9051e+02,  ..., -1.3036e+02,\n",
       "            4.8310e+02, -5.0240e+02],\n",
       "          [-9.9437e+02,  4.9689e+02, -9.8474e+02,  ..., -5.3228e+02,\n",
       "            1.7382e+02,  1.2055e+03]],\n",
       "\n",
       "         [[ 1.3588e+02, -1.9370e+03,  7.3171e+02,  ...,  5.5247e+02,\n",
       "            1.8802e+03,  9.5168e+02],\n",
       "          [-8.0666e+02,  7.2207e+02, -1.3947e+03,  ..., -1.4335e+03,\n",
       "            1.2807e+03,  1.2755e+02],\n",
       "          [-1.1958e+03, -1.6148e+02, -1.4504e+03,  ..., -6.0642e+02,\n",
       "            3.1106e+02, -3.4109e+02],\n",
       "          ...,\n",
       "          [ 2.5913e+02,  2.2286e+03,  6.7131e+02,  ...,  1.0158e+03,\n",
       "            1.1372e+03,  7.2240e+02],\n",
       "          [-1.1546e+03, -1.2427e+03, -1.8598e+02,  ...,  1.1283e+03,\n",
       "           -1.3018e+03, -2.4084e+02],\n",
       "          [-5.1392e+02,  7.7180e+01,  6.6677e+02,  ..., -7.4986e+01,\n",
       "           -3.5700e+02, -1.0270e+03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.7205e+02,  5.9433e+02, -7.6123e+01,  ...,  1.2720e+03,\n",
       "           -4.6840e+02,  7.8788e+02],\n",
       "          [-5.0211e+02, -5.7801e+02, -1.3289e+03,  ...,  3.1160e+01,\n",
       "           -1.5620e+02, -2.0854e+02],\n",
       "          [ 6.5297e+02,  1.0807e+03,  5.6166e+02,  ...,  9.4922e+02,\n",
       "            9.8257e+02,  6.0859e+02],\n",
       "          ...,\n",
       "          [ 8.2581e+02, -4.0521e+02, -1.2523e+03,  ..., -5.1763e+01,\n",
       "            1.7178e+03,  6.8115e+02],\n",
       "          [ 1.4349e+03,  3.6231e+02, -9.9637e+02,  ..., -1.1759e+03,\n",
       "            8.0727e+02, -1.0673e+03],\n",
       "          [ 6.7554e+02, -1.8563e+03, -1.8754e+03,  ...,  1.0983e+03,\n",
       "           -4.2505e+00,  5.8456e+02]],\n",
       "\n",
       "         [[ 7.9041e+01, -1.0577e+03, -4.4350e+02,  ...,  9.6007e+02,\n",
       "            8.0939e+01, -2.0455e+03],\n",
       "          [-2.9589e+01,  8.7656e+02, -1.0343e+03,  ...,  3.2571e+02,\n",
       "            1.8400e+03,  2.3466e+03],\n",
       "          [ 1.7119e+02,  2.4191e+02, -1.3793e+03,  ...,  2.8002e+01,\n",
       "            3.7505e+02,  9.7164e+02],\n",
       "          ...,\n",
       "          [ 1.2120e+02,  1.5899e+02,  8.2698e+02,  ...,  7.4499e+02,\n",
       "            2.8767e+02,  2.0393e+03],\n",
       "          [ 7.3691e+02,  1.6012e+03,  1.9692e+03,  ..., -8.3601e+01,\n",
       "           -1.1078e+03,  4.5385e+02],\n",
       "          [-1.8054e+03,  4.0757e+02,  9.6771e+02,  ...,  1.1922e+03,\n",
       "           -9.1024e+02,  8.7552e+02]],\n",
       "\n",
       "         [[ 1.5566e+03,  2.2138e+03,  7.4037e+02,  ..., -1.3133e+03,\n",
       "           -2.9704e+02,  7.8846e+02],\n",
       "          [-1.0904e+02, -4.9396e+02, -2.4919e+03,  ...,  4.5652e+02,\n",
       "            2.5395e+02,  5.5559e+02],\n",
       "          [ 1.1920e+03,  1.0697e+03,  1.4470e+03,  ...,  3.5544e+02,\n",
       "            1.0686e+03, -3.9369e+02],\n",
       "          ...,\n",
       "          [ 5.5979e+02, -5.2577e+02,  5.5982e+01,  ..., -1.4072e+03,\n",
       "            5.3599e+02,  8.0040e+01],\n",
       "          [-1.2346e+03,  1.1098e+03, -8.4013e+02,  ...,  1.4879e+02,\n",
       "            6.0796e+02,  1.3220e+03],\n",
       "          [ 1.8302e+02,  1.1361e+03,  7.8535e+02,  ...,  1.3208e+03,\n",
       "           -1.7019e+03, -4.5840e+02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.7680e+03, -6.4776e+02, -1.0689e+03,  ...,  2.0462e+03,\n",
       "           -1.7094e+03,  9.8243e+02],\n",
       "          [-1.1781e+03, -1.0583e+03, -6.8432e+02,  ...,  9.1034e+02,\n",
       "            2.1865e+02,  1.2784e+03],\n",
       "          [ 9.4267e+02, -1.6033e+00,  1.1583e+02,  ...,  5.6667e+02,\n",
       "            1.9334e+03,  7.8834e+02],\n",
       "          ...,\n",
       "          [ 1.2979e+03,  1.1270e+03,  6.7918e+02,  ..., -6.0098e+02,\n",
       "            1.6048e+02, -8.4058e+01],\n",
       "          [ 1.3797e+03, -4.8513e+01, -9.0174e+02,  ..., -1.0331e+02,\n",
       "           -5.5410e+02, -1.2190e+03],\n",
       "          [-4.5859e+02,  1.7611e+03, -1.2835e+03,  ..., -2.8173e+02,\n",
       "            7.7439e+02, -5.0925e+02]],\n",
       "\n",
       "         [[-2.6311e+03, -1.0850e+03, -1.1786e+03,  ..., -2.1414e+03,\n",
       "            7.1897e+02,  1.2376e+03],\n",
       "          [-9.4215e+02,  1.2760e+03,  1.8629e+02,  ..., -3.1825e+01,\n",
       "           -1.1409e+03,  5.3239e+02],\n",
       "          [ 1.6345e+03, -1.2970e+03, -4.3535e+02,  ..., -1.0356e+03,\n",
       "            1.5063e+03, -3.2964e+03],\n",
       "          ...,\n",
       "          [ 1.0395e+03, -8.5763e+01, -6.2328e+02,  ...,  1.3553e+03,\n",
       "           -6.0370e+02, -1.1337e+02],\n",
       "          [ 8.8757e+02,  2.3850e+03, -6.7689e+02,  ..., -2.9265e+02,\n",
       "            1.1382e+03, -2.2413e+02],\n",
       "          [-7.6962e+02,  3.1571e+03,  2.0410e+02,  ...,  1.1289e+03,\n",
       "           -5.1278e+02,  1.3619e+03]],\n",
       "\n",
       "         [[-1.0633e+03,  5.6335e+01, -3.8833e+02,  ..., -1.5853e+03,\n",
       "           -1.8019e+03,  1.2685e+03],\n",
       "          [-1.4607e+03, -4.1525e+01,  7.2065e+02,  ...,  7.9385e+02,\n",
       "            3.1315e+02, -5.1580e+02],\n",
       "          [-8.1504e+02,  5.2619e+02,  5.3534e+02,  ..., -8.1855e+01,\n",
       "            3.6280e+02,  1.3150e+03],\n",
       "          ...,\n",
       "          [-1.1829e+03,  6.9511e+02,  1.5393e+02,  ..., -9.6969e+01,\n",
       "            7.3633e+02, -1.7010e+03],\n",
       "          [-1.0191e+03, -4.5276e+02,  1.1005e+03,  ..., -8.6556e+01,\n",
       "           -1.0567e+03, -4.6494e+02],\n",
       "          [-2.9696e+02,  3.0707e+02,  5.6852e+01,  ...,  1.7767e+03,\n",
       "           -1.8081e+02, -5.9859e+02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.3870e+02,  1.1863e+03,  1.5738e+03,  ...,  6.9489e+02,\n",
       "           -6.4640e+02, -4.9730e+02],\n",
       "          [ 7.1664e+01,  1.6130e+03,  1.2081e+03,  ..., -2.3178e+03,\n",
       "            4.2842e+02,  1.1252e+03],\n",
       "          [-2.2147e+02, -7.2662e+02,  2.0746e+03,  ...,  9.0828e+02,\n",
       "           -1.6706e+01, -1.6729e+02],\n",
       "          ...,\n",
       "          [-1.9926e+03,  2.2485e+03, -1.5153e+03,  ..., -7.5774e+02,\n",
       "           -8.3975e+01, -1.0446e+02],\n",
       "          [ 1.2612e+03, -6.7792e+02,  1.4476e+03,  ..., -6.9469e+02,\n",
       "           -2.7348e+03,  1.4140e+03],\n",
       "          [ 1.1620e+03, -1.8755e+02, -1.8975e+02,  ...,  1.5877e+03,\n",
       "            9.4110e+02, -2.0151e+03]],\n",
       "\n",
       "         [[-1.4373e+03, -5.7108e+02, -1.8568e+02,  ...,  1.7587e+02,\n",
       "           -1.4004e+03,  4.3722e+02],\n",
       "          [ 1.0538e+03, -4.9836e+02,  1.9125e+03,  ...,  1.3909e+03,\n",
       "           -2.1624e+03,  1.5685e+03],\n",
       "          [-1.9256e+03,  1.6159e+03, -5.9105e+02,  ...,  4.3585e+00,\n",
       "           -3.1409e+02,  1.4691e+02],\n",
       "          ...,\n",
       "          [ 1.8863e+03,  3.9311e+01,  1.2853e+03,  ...,  7.2634e+02,\n",
       "            1.1648e+03,  4.9325e+02],\n",
       "          [-5.7548e+02, -1.3923e+02, -7.1992e+02,  ..., -2.1415e+02,\n",
       "            8.8171e+02, -1.9520e+02],\n",
       "          [ 9.5171e+02, -2.2148e+02,  1.5638e+03,  ..., -9.4027e+02,\n",
       "           -2.3080e+02, -4.6545e+02]],\n",
       "\n",
       "         [[-2.6850e+02,  1.1842e+02,  2.8542e+03,  ...,  1.2950e+03,\n",
       "            4.6072e+01, -2.3408e+01],\n",
       "          [-3.1662e+02, -1.3477e+03,  1.1256e+03,  ..., -1.0929e+02,\n",
       "            4.2484e+02,  9.8662e+02],\n",
       "          [ 1.2572e+03,  2.6096e+02, -1.1294e+03,  ...,  3.7893e+02,\n",
       "            1.5591e+03, -1.3628e+03],\n",
       "          ...,\n",
       "          [ 1.3898e+03, -1.3383e+03,  2.2634e+02,  ...,  6.0867e+02,\n",
       "            1.5327e+02,  6.4310e+02],\n",
       "          [ 9.3367e+02, -1.7266e+03,  7.1451e+02,  ..., -1.0135e+02,\n",
       "            7.3278e+01,  7.7323e+01],\n",
       "          [ 1.7043e+03,  1.0881e+02, -1.1619e+03,  ...,  3.6519e+02,\n",
       "            1.3163e+03, -2.0146e+03]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1986e+03,  1.0371e+03,  4.4835e+01,  ..., -2.9765e+02,\n",
       "            2.2422e+03,  1.4407e+03],\n",
       "          [ 9.2992e+02,  4.3946e+01, -2.1580e+02,  ...,  7.2822e+02,\n",
       "           -9.9761e+02,  4.9350e+01],\n",
       "          [ 7.9975e+01, -8.3448e+02,  1.2119e+03,  ..., -1.0979e+03,\n",
       "            7.2088e+02,  2.4808e+02],\n",
       "          ...,\n",
       "          [-1.8439e+02, -5.7938e+02, -2.2842e+01,  ...,  1.9430e+03,\n",
       "            5.4589e+02, -4.4105e+02],\n",
       "          [-3.9641e+02, -1.2735e+03,  5.0572e+02,  ...,  6.8575e+02,\n",
       "            5.2686e+02, -6.7953e+02],\n",
       "          [ 7.1586e+01, -9.3607e+02,  2.1614e+02,  ...,  1.5736e+03,\n",
       "            7.8956e+02, -4.0975e+02]],\n",
       "\n",
       "         [[ 3.0503e+01, -8.9397e+02, -2.1921e+02,  ...,  1.9637e+03,\n",
       "           -1.2392e+03, -7.5728e+02],\n",
       "          [-1.3061e+03,  3.9432e+01,  4.8271e+02,  ..., -1.3245e+03,\n",
       "           -1.4260e+03, -6.9652e+01],\n",
       "          [-3.4026e+02, -1.3172e+03, -1.4162e+02,  ..., -3.1868e+02,\n",
       "            7.3099e+02, -8.7445e+02],\n",
       "          ...,\n",
       "          [ 5.5422e+02, -3.9156e+02, -7.0632e+02,  ...,  1.1191e+03,\n",
       "            1.0454e+03, -5.4612e+02],\n",
       "          [-1.4276e+03,  7.1345e+02,  4.4740e+02,  ...,  1.3587e+03,\n",
       "            8.1273e+02,  2.2244e+02],\n",
       "          [ 8.4547e+02,  5.1651e+02, -1.5593e+02,  ..., -8.8505e+02,\n",
       "           -4.9709e+02,  3.4517e+02]],\n",
       "\n",
       "         [[ 1.6608e+03, -1.7264e+03,  1.2193e+03,  ...,  1.4727e+03,\n",
       "           -1.7378e+03,  6.9091e+02],\n",
       "          [ 4.7443e+02,  5.2210e+02,  7.2536e+02,  ...,  1.4058e+02,\n",
       "            3.4847e+02, -5.7971e+02],\n",
       "          [-7.5052e+01,  9.2351e+02,  4.9118e+01,  ..., -4.2101e+02,\n",
       "            1.0772e+03, -1.8347e+03],\n",
       "          ...,\n",
       "          [ 4.6096e+02,  7.1105e+02,  4.9058e+02,  ...,  3.6054e+01,\n",
       "            2.1003e+01,  1.9775e+01],\n",
       "          [-9.1620e+02, -1.4843e+02, -1.0765e+03,  ...,  9.1332e+02,\n",
       "           -1.6884e+03, -8.7070e+02],\n",
       "          [-2.9944e+03, -5.8090e+02,  1.0532e+03,  ...,  7.2772e+01,\n",
       "           -5.9321e+02,  2.8091e+02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.6390e+01, -3.6880e+01, -1.1803e+03,  ...,  4.0158e+02,\n",
       "           -7.8310e+02, -5.9248e+02],\n",
       "          [ 1.7611e+03,  1.0011e+03, -1.0967e+03,  ...,  1.3172e+02,\n",
       "           -3.5529e+02, -3.7256e+02],\n",
       "          [ 4.1704e+02, -1.1587e+03,  1.2673e+02,  ..., -5.9835e+01,\n",
       "            1.1282e+03, -2.3941e+02],\n",
       "          ...,\n",
       "          [-1.3859e+03,  7.6258e+02,  1.3472e+02,  ...,  1.0828e+02,\n",
       "            3.1040e+02,  1.5432e+03],\n",
       "          [ 5.4152e+02, -5.2319e+02,  2.9799e+02,  ..., -5.3055e+02,\n",
       "           -1.2795e+03,  4.8075e+02],\n",
       "          [ 4.0214e+02,  7.7955e+02,  3.5990e+02,  ...,  1.7243e+03,\n",
       "            7.1600e+02,  3.8254e+02]],\n",
       "\n",
       "         [[-1.4811e+03,  1.1855e+03,  5.1859e+02,  ...,  8.7600e+01,\n",
       "            6.5276e+02,  2.0953e+02],\n",
       "          [ 5.0627e+02,  5.8858e+02,  7.2290e+02,  ..., -1.5098e+02,\n",
       "            4.5784e+02, -1.2028e+03],\n",
       "          [ 7.4310e+02,  8.4681e+01,  6.9916e+02,  ..., -3.2872e+02,\n",
       "            1.5725e+02, -1.8584e+02],\n",
       "          ...,\n",
       "          [ 1.9885e+02,  3.1138e+01, -3.7646e+02,  ...,  7.1134e+02,\n",
       "           -2.0358e+01, -5.1051e+02],\n",
       "          [ 1.4481e+02, -4.1300e+02, -1.1404e+03,  ...,  1.3571e+03,\n",
       "            1.6090e-01, -7.7324e+02],\n",
       "          [-8.5683e+02, -1.5684e+03,  8.9079e+02,  ...,  4.5064e+02,\n",
       "           -1.0584e+03, -4.6856e+02]],\n",
       "\n",
       "         [[ 3.2136e+02,  1.3585e+03,  7.6148e+02,  ..., -9.6042e+02,\n",
       "           -2.4771e+02,  2.1712e+03],\n",
       "          [ 1.6787e+03, -1.7062e+03,  9.6055e+02,  ..., -9.6616e+02,\n",
       "            6.7521e+02, -2.5275e+02],\n",
       "          [ 1.7110e+02, -4.8301e+02,  1.5082e+03,  ..., -8.0564e+02,\n",
       "            1.0164e+02, -1.6025e+02],\n",
       "          ...,\n",
       "          [ 1.4616e+03,  2.6045e+03,  2.8760e+02,  ..., -2.8984e+02,\n",
       "            2.2596e+03, -6.2312e+02],\n",
       "          [-8.9761e+02, -1.2836e+01, -8.7470e+02,  ...,  6.8601e+02,\n",
       "           -4.6778e+02,  6.5494e+02],\n",
       "          [-1.7101e+02, -4.6965e+02, -4.5972e+02,  ..., -5.5508e+02,\n",
       "           -6.5008e+02,  1.2220e+03]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0756e+03, -1.8061e+03, -7.4611e+02,  ...,  1.6557e+03,\n",
       "           -1.5460e+03,  1.9453e+03],\n",
       "          [ 9.8677e+02, -8.0328e+02, -2.0979e+02,  ...,  6.8572e+01,\n",
       "            8.4027e+01, -1.8432e+02],\n",
       "          [ 7.9343e+02,  2.8221e+02, -5.5287e+02,  ..., -5.9124e+02,\n",
       "            4.8230e+02,  2.3523e+02],\n",
       "          ...,\n",
       "          [ 1.7365e+02,  2.4305e+02, -1.5432e+03,  ...,  1.0623e+03,\n",
       "            5.7249e+02, -8.4468e+01],\n",
       "          [ 9.7690e+02, -1.9272e+02, -1.0097e+03,  ..., -4.3071e+02,\n",
       "            7.5080e+02,  2.0079e+03],\n",
       "          [ 1.3459e+03,  1.7119e+03, -9.3428e+02,  ..., -8.7370e+02,\n",
       "           -3.8683e+02,  1.3286e+03]],\n",
       "\n",
       "         [[ 1.4207e+03,  1.0460e+03, -1.1914e+03,  ...,  1.1817e+03,\n",
       "            1.7168e+03, -8.5064e+02],\n",
       "          [ 1.4179e+03,  1.8603e+03, -5.0616e+02,  ...,  2.6709e+03,\n",
       "            1.0903e+03, -6.3386e+02],\n",
       "          [-4.8787e+02, -5.0856e+02, -1.0517e+03,  ..., -1.2105e+03,\n",
       "            3.5421e+02,  4.9916e+02],\n",
       "          ...,\n",
       "          [ 1.0096e+03,  3.5943e+00,  1.4834e+03,  ..., -1.2035e+03,\n",
       "           -4.7320e+02, -1.1418e+01],\n",
       "          [ 4.6336e+02,  8.1952e+02, -7.4803e+02,  ..., -7.6056e+01,\n",
       "            1.2621e+03,  1.4892e+03],\n",
       "          [ 4.2286e+02, -6.2096e+02,  1.1989e+03,  ..., -2.3025e+03,\n",
       "           -8.7186e+02, -6.1170e+02]],\n",
       "\n",
       "         [[-6.7003e+02,  2.2710e+03, -4.6787e+02,  ...,  1.1557e+03,\n",
       "            5.8693e+01, -1.4468e+03],\n",
       "          [ 1.1422e+03, -1.3760e+03, -1.2470e+03,  ..., -2.4008e+03,\n",
       "           -7.2388e+02, -4.9281e+02],\n",
       "          [-6.7848e+02, -9.2343e+02,  6.4552e+02,  ..., -7.3183e+02,\n",
       "           -1.6299e+03, -4.0850e+02],\n",
       "          ...,\n",
       "          [ 1.9166e+02, -9.3757e+02,  2.0747e+03,  ...,  5.3363e+01,\n",
       "           -3.1388e+02, -1.8225e+03],\n",
       "          [-2.6861e+03, -2.4107e+02, -1.0196e+03,  ...,  6.2024e+01,\n",
       "           -2.7224e+02, -3.4293e+02],\n",
       "          [-3.8616e+01, -1.1126e+03,  1.0498e+03,  ...,  7.6755e+02,\n",
       "           -4.5746e+01,  2.2025e+02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.9916e+02, -1.1164e+02,  1.1829e+03,  ..., -9.9809e+02,\n",
       "            9.7758e+02,  3.2956e+02],\n",
       "          [-9.5370e+01,  4.4157e+02,  6.0180e+02,  ...,  1.8821e+02,\n",
       "            1.2306e+03,  9.9710e+02],\n",
       "          [ 6.5999e+02, -8.5655e+02,  1.1387e+03,  ...,  9.9840e+02,\n",
       "           -7.9763e+02, -1.2590e+03],\n",
       "          ...,\n",
       "          [-1.2065e+02,  6.1343e+02, -2.0673e+03,  ...,  1.6338e+02,\n",
       "            5.6253e+02,  4.9257e+02],\n",
       "          [ 1.1212e+03, -1.0798e+03,  5.6186e+02,  ...,  7.9379e+02,\n",
       "           -1.4972e+02,  5.9106e+01],\n",
       "          [-1.6248e+03,  1.6320e+03, -1.3382e+03,  ...,  5.6323e+02,\n",
       "            9.0885e+02,  1.0954e+03]],\n",
       "\n",
       "         [[-3.7365e+02,  1.7607e+02,  6.6198e+01,  ..., -1.1765e+03,\n",
       "           -8.6715e+02, -7.3246e+02],\n",
       "          [-7.8240e+02, -4.0059e+01,  1.0916e+03,  ..., -2.1019e+03,\n",
       "            1.1961e+02,  2.9049e+02],\n",
       "          [-1.9013e+03,  7.8127e+02,  3.9479e+02,  ..., -2.1474e+02,\n",
       "           -7.9874e+02, -2.6793e+02],\n",
       "          ...,\n",
       "          [-1.5410e+03,  1.0847e+03, -1.2925e+03,  ..., -5.0726e+02,\n",
       "           -1.8922e+02,  3.0833e+02],\n",
       "          [ 3.9856e+02,  1.1150e+03,  1.5994e+03,  ..., -2.2055e+01,\n",
       "            2.7304e+03,  1.3969e+02],\n",
       "          [-6.9691e+01,  7.1869e+02,  1.8330e+01,  ...,  8.6317e+02,\n",
       "            1.3244e+03,  1.6063e+02]],\n",
       "\n",
       "         [[ 4.4599e+01,  1.3595e+03, -1.7643e+02,  ..., -1.1014e+02,\n",
       "            3.2692e+02,  5.3512e+02],\n",
       "          [ 3.2080e+02,  7.1376e+02,  5.2909e+02,  ...,  6.8923e+01,\n",
       "            8.3814e+02, -4.2181e+02],\n",
       "          [-1.9453e+03, -1.5644e+03, -4.4833e+02,  ..., -1.2962e+03,\n",
       "            1.0965e+03,  5.9103e+02],\n",
       "          ...,\n",
       "          [ 6.3106e+02,  1.4194e+03,  1.5535e+03,  ...,  1.3558e+00,\n",
       "            5.8536e+02, -5.0852e+02],\n",
       "          [-5.0783e+02, -7.3516e+02,  9.9409e+01,  ...,  4.6521e+02,\n",
       "           -1.4710e+03,  2.7257e+02],\n",
       "          [-9.9952e+02, -1.2357e+03, -4.5516e+01,  ...,  1.3857e+03,\n",
       "           -5.6186e+01, -1.4484e+03]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn([32, 512, 32, 32])\n",
    "b = torch.randn([32, 512, 32, 32])\n",
    "a *1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def load_kb(start, end):\n",
    "    KB_FILE = 'D:\\Research\\Race\\ClimaX\\kb_2048.csv'\n",
    "    skiprows = 8592\n",
    "    df = pd.read_csv(KB_FILE, nrows=skiprows*(end-start), skiprows=start*skiprows)\n",
    "    return torch.tensor(np.array(df))\n",
    "\n",
    "kb = []\n",
    "\n",
    "for i in range(10):\n",
    "    t = load_kb(i ,i+1)\n",
    "    t = t.to('cuda:0')\n",
    "    t = t.float()\n",
    "    kb.append(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climaX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
